<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Multi-Model AI Chat Interface</title>
    <!-- Previous CSS styles remain exactly the same -->
</head>
<body>
    <div class="header">
        <div class="model-selector">
            <button class="model-button" onclick="toggleDropdown()" id="currentModel">
                Select AI Model
            </button>
            <div class="model-dropdown" id="modelDropdown">
                <div class="model-option" onclick="selectModel('chat')">
                    <div class="model-icon"></div>
                    ChatAI
                </div>
                <div class="model-option" onclick="selectModel('assistant')">
                    <div class="model-icon"></div>
                    Assistant
                </div>
                <div class="model-option" onclick="selectModel('completion')">
                    <div class="model-icon"></div>
                    Completion
                </div>
            </div>
        </div>
    </div>

    <!-- Previous HTML structure remains the same -->

    <script>
        let currentModel = null;
        const textarea = document.getElementById('userInput');
        const chatContainer = document.getElementById('chatContainer');
        const typingIndicator = document.getElementById('typingIndicator');

        // Using reliable free endpoints
        const API_ENDPOINTS = {
            'chat': 'https://free.churchless.tech/v1/chat/completions',
            'assistant': 'https://api.openai-proxy.com/v1/chat/completions',
            'completion': 'https://api.deepinfra.com/v1/inference/chat'
        };

        async function generateResponse(input) {
            const endpoint = API_ENDPOINTS[currentModel];
            
            const payload = {
                messages: [{
                    role: "user",
                    content: input
                }],
                model: "gpt-3.5-turbo",
                temperature: 0.7,
                max_tokens: 150
            };

            try {
                const response = await fetch(endpoint, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify(payload)
                });

                if (!response.ok) {
                    throw new Error('Network response was not ok');
                }

                const data = await response.json();
                return data.choices[0].message.content;
            } catch (error) {
                // Fallback to backup API if primary fails
                const backupEndpoint = 'https://api.free-ai.chat/v1/chat/completions';
                const backupResponse = await fetch(backupEndpoint, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify(payload)
                });
                
                const backupData = await backupResponse.json();
                return backupData.choices[0].message.content;
            }
        }

        function toggleDropdown() {
            document.getElementById('modelDropdown').classList.toggle('show');
        }

        function selectModel(model) {
            currentModel = model;
            document.getElementById('currentModel').textContent = model.charAt(0).toUpperCase() + model.slice(1);
            document.getElementById('modelDropdown').classList.remove('show');
            addMessage(`Now using ${model.charAt(0).toUpperCase() + model.slice(1)} model`, 'bot');
        }

        async function sendMessage() {
            const userInput = textarea.value.trim();
            if (!userInput) return;
            if (!currentModel) {
                addMessage('Please select an AI model first!', 'bot');
                return;
            }

            addMessage(userInput, 'user');
            textarea.value = '';
            typingIndicator.style.display = 'block';
            chatContainer.scrollTop = chatContainer.scrollHeight;

            try {
                const response = await generateResponse(userInput);
                typingIndicator.style.display = 'none';
                addMessage(response, 'bot');
            } catch (error) {
                typingIndicator.style.display = 'none';
                addMessage('Switching to backup model...', 'bot');
                try {
                    const backupResponse = await generateResponse(userInput);
                    addMessage(backupResponse, 'bot');
                } catch (backupError) {
                    addMessage('Please try again in a moment.', 'bot');
                }
            }
        }

        textarea.addEventListener('keypress', function(e) {
            if (e.key === 'Enter' && !e.shiftKey) {
                e.preventDefault();
                sendMessage();
            }
        });

        function addMessage(text, sender) {
            const messageDiv = document.createElement('div');
            messageDiv.className = `message ${sender}`;
            messageDiv.innerHTML = `
                <div class="message-bubble">
                    ${text}
                </div>
            `;
            chatContainer.insertBefore(messageDiv, typingIndicator);
            chatContainer.scrollTop = chatContainer.scrollHeight;
        }

        // Close dropdown when clicking outside
        window.onclick = function(event) {
            if (!event.target.matches('.model-button')) {
                const dropdowns = document.getElementsByClassName('model-dropdown');
                Array.from(dropdowns).forEach(dropdown => {
                    if (dropdown.classList.contains('show')) {
                        dropdown.classList.remove('show');
                    }
                });
            }
        }
    </script>
</body>
</html>
